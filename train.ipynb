{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgw = 64\n",
    "imgh = 64\n",
    "nb_train_samples = 8000\n",
    "nb_test_samples = 2000\n",
    "epochs = 25\n",
    "batch_size = 40\n",
    "input_shape = (64,64,3)\n",
    "\n",
    "DNN_model_path = 'model/dnn_model.h5'\n",
    "CNN_model_path = 'model/cnn_model.h5'\n",
    "TARGET_IMAGE = 'dataset\\Tungro\\TUNGRO1_004.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4747 images belonging to 4 classes.\n",
      "Found 1185 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "main_path = 'dataset'\n",
    "generator = ImageDataGenerator(rescale=1./255,\n",
    "                               validation_split=0.2)\n",
    "\n",
    "train_datagen = generator.flow_from_directory(main_path,\n",
    "                                              target_size=(imgw,imgh),\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=32,\n",
    "                                              subset='training')\n",
    "\n",
    "valid_datagen = generator.flow_from_directory(main_path,\n",
    "                                              target_size=(imgw,imgh),\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=16,\n",
    "                                              subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: (32, 64, 64, 3)\n",
      "Labels batch shape: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_datagen:\n",
    "    print('Data batch shape:', data_batch.shape)\n",
    "    print('Labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(path):\n",
    "    img = load_img(path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,)+x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1572992   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1581313 (6.03 MB)\n",
      "Trainable params: 1581313 (6.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = Sequential()\n",
    "\n",
    "dnn_model.add(Flatten(input_shape = input_shape))\n",
    "dnn_model.add(Dense(128))\n",
    "dnn_model.add(Activation('relu'))\n",
    "dnn_model.add(Dropout(0.5))\n",
    "dnn_model.add(Dense(64))\n",
    "dnn_model.add(Activation('relu'))\n",
    "dnn_model.add(Dropout(0.5))\n",
    "dnn_model.add(Dense(1))\n",
    "dnn_model.add(Activation('tanh'))\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dnn_model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilda\\AppData\\Local\\Temp\\ipykernel_30636\\4054633166.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  dnn_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "149/149 [==============================] - 35s 232ms/step - loss: 3.8944 - accuracy: 0.7413 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 2/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8602 - accuracy: 0.7489 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 3/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8589 - accuracy: 0.7491 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 4/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8589 - accuracy: 0.7496 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 5/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8572 - accuracy: 0.7498 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 6/25\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 3.8571 - accuracy: 0.7499 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 7/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8594 - accuracy: 0.7498 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 8/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8624 - accuracy: 0.7495 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 9/25\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 3.8595 - accuracy: 0.7497 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 10/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8567 - accuracy: 0.7497 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 11/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8571 - accuracy: 0.7497 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 12/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8556 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 13/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8571 - accuracy: 0.7499 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 14/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8562 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 15/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8578 - accuracy: 0.7499 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8559 - accuracy: 0.7499 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 17/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8562 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 18/25\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 3.8610 - accuracy: 0.7497 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 19/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8587 - accuracy: 0.7498 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 20/25\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 3.8561 - accuracy: 0.7498 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 21/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8562 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 22/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8578 - accuracy: 0.7498 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 23/25\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 3.8601 - accuracy: 0.7497 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 24/25\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 3.8562 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n",
      "Epoch 25/25\n",
      "149/149 [==============================] - 6s 42ms/step - loss: 3.8562 - accuracy: 0.7500 - val_loss: 3.8562 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16d72f20f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.fit_generator(\n",
    "        train_datagen,\n",
    "        epochs = epochs,\n",
    "        validation_data = valid_datagen\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.save_weights(DNN_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 4s 29ms/step - loss: 3.8562 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.856235980987549, 0.75]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_model(model_path = DNN_model_path, img_path = TARGET_IMAGE):\n",
    "#     img = load_img(img_path, target_size = (imgw, imgh))\n",
    "#     img = img_to_array(img)/255\n",
    "#     img = img.reshape((1,) + img.shape)\n",
    "    \n",
    "#     model = dnn_model((64,64,3))\n",
    "#     model.load_weights(DNN_model_path)\n",
    "    \n",
    "#     print(model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Activation, Flatten, Dense, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wilda\\miniconda3\\envs\\tensorflow\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 6, 6, 96)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 256)         614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              1052672   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25682188 (97.97 MB)\n",
      "Trainable params: 25682188 (97.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model using TensorFlow/Keras\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(96, kernel_size=11, strides=4, activation='relu', input_shape=input_shape))\n",
    "cnn_model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "cnn_model.add(Conv2D(256, kernel_size=5, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "cnn_model.add(Conv2D(384, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(384, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling2D((3,2), padding='same'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(4096, activation=\"relu\"))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(4096, activation=\"relu\"))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1000, activation=\"relu\"))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(4, activation=\"softmax\"))\n",
    "cnn_model.summary()\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if logs.get('val_accuracy') > 0.99:\n",
    "#             self.model.stop_training = True\n",
    "            \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=10, delta=0.001, max_acc = 0.99):\n",
    "        super(myCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.wait = 0\n",
    "        self.best_val_acc = -float('inf')\n",
    "        self.max_acc = max_acc\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current_val_acc = logs.get('val_accuracy')\n",
    "        if current_val_acc is None:\n",
    "            return\n",
    "\n",
    "        if current_val_acc > self.best_val_acc + self.delta:\n",
    "            self.best_val_acc = current_val_acc\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.model.stop_training = True\n",
    "                print(\"\\nTraining stopped as val_accuracy did not improve for {} epochs.\".format(self.patience))\n",
    "            \n",
    "        if logs.get('val_accuracy') >=  self.max_acc and logs.get('accuracy') >=  self.max_acc:\n",
    "            self.model.stop_training = True\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = myCallback()\n",
    "cnn_history = cnn_model.fit_generator(train_datagen,\n",
    "          epochs=10,\n",
    "          validation_data=valid_datagen,\n",
    "          callbacks=callback)\n",
    "cnn_history.save_weights(CNN_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 9s 63ms/step - loss: 1.3831 - accuracy: 0.2696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.383091926574707, 0.26964399218559265]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(train_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_loss = [['accuracy', 'val_accuracy'],\n",
    "            ['loss', 'val_loss']]\n",
    "\n",
    "for i in acc_loss:\n",
    "    \n",
    "    plt.plot(dnn_model.history[i[0]], 'g-o')\n",
    "    plt.plot(dnn_model.history[i[1]], 'b-+')\n",
    "    plt.title(f'model {i[0]} and {i[1]}')\n",
    "    plt.ylabel(f'{i[0]}')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
